# Werewolf Game - Production Environment Configuration
# Copy this file to .env and fill in your API keys

# AI Provider Configuration
# Choose your AI provider: 'gemini', 'openai', or 'ollama'
AI_PROVIDER=gemini

# =============================================================================
# GEMINI CONFIGURATION (Google AI)
# =============================================================================
# Get your API key from: https://makersuite.google.com/app/apikey
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-2.5-flash

# =============================================================================
# OPENAI COMPATIBLE CONFIGURATION
# =============================================================================
# For OpenAI: Get your API key from https://platform.openai.com/api-keys
# For OpenRouter: Get your API key from https://openrouter.ai/keys
# For Together AI: Get your API key from https://api.together.xyz/
# For other providers: Check their documentation for API keys

# OpenAI (Default)
OPENAI_API_KEY=sk-your-openai-key-here
OPENAI_MODEL=gpt-4o-mini
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_HOST=api.openai.com

# OpenRouter Example (uncomment and modify to use)
# OPENAI_API_KEY=sk-or-v1-your-openrouter-key
# OPENAI_MODEL=anthropic/claude-3-haiku
# OPENAI_BASE_URL=https://openrouter.ai/api/v1
# OPENAI_HOST=openrouter.ai

# Together AI Example (uncomment and modify to use)
# OPENAI_API_KEY=your-together-key
# OPENAI_MODEL=meta-llama/Llama-3.2-3B-Instruct-Turbo
# OPENAI_BASE_URL=https://api.together.xyz/v1
# OPENAI_HOST=api.together.xyz

# =============================================================================
# OLLAMA CONFIGURATION (Local AI)
# =============================================================================
# Make sure Ollama is running locally or on your server
# For local: http://localhost:11434
# For external: http://your-ollama-server:11434
OLLAMA_BASE_URL=http://ollama:11434
OLLAMA_MODEL=gemma3:4b

# =============================================================================
# DEVELOPMENT CONFIGURATION
# =============================================================================
# For development mode, you can still use the old REACT_APP_ variables
# These will be ignored in production (nginx proxy mode)

# Development Gemini
REACT_APP_AI_PROVIDER=gemini
REACT_APP_GEMINI_API_KEY=your_gemini_api_key_here
REACT_APP_GEMINI_MODEL=gemini-2.5-flash

# Development OpenAI
# REACT_APP_AI_PROVIDER=openai
# REACT_APP_OPENAI_API_KEY=your_openai_api_key_here
# REACT_APP_OPENAI_MODEL=gpt-4o-mini
# REACT_APP_OPENAI_BASE_URL=https://api.openai.com/v1

# Development Ollama
# REACT_APP_AI_PROVIDER=ollama
# REACT_APP_OLLAMA_BASE_URL=http://localhost:11434
# REACT_APP_OLLAMA_MODEL=gemma3:4b 